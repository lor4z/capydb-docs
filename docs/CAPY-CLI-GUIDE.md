# CapyDb CLI - Guia Completo

> Ferramenta de linha de comando para gerenciamento de migrations com Liquibase e Entity Framework Core

## üìã √çndice

- [Instala√ß√£o](#-instala√ß√£o)
- [Comandos Principais](#-comandos-principais)
- [Migrations](#-migrations)
- [Opera√ß√µes de Banco](#Ô∏è-opera√ß√µes-de-banco)
- [Utilit√°rios](#Ô∏è-utilit√°rios)
- [Sistema de Autores](#-sistema-de-autores)
- [Configura√ß√£o Avan√ßada](#Ô∏è-configura√ß√£o-avan√ßada)
- [Troubleshooting](#-troubleshooting)

---

## üöÄ Instala√ß√£o

### Como Ferramenta Global

```bash
# Compilar e empacotar
dotnet pack src/CapyDb.Cli/CapyDb.Cli.csproj -o nupkg

# Instalar globalmente
dotnet tool install -g capydb.cli --add-source ./nupkg

# Verificar instala√ß√£o
cap --version
```

### Execu√ß√£o Direta

```bash
# Executar sem instalar
dotnet run --project src/CapyDb.Cli -- [comandos]
```

---

## üìñ Comandos Principais

### Informa√ß√µes Gerais

```bash
# Vers√£o do CapyDb
cap --version

# Ajuda completa
cap --help

# Verificar pr√©-requisitos
cap doctor

# Despedida (ASCII art)
cap bye
```

---

## üìù Migrations

### 1. Criar Nova Migration

```bash
# Sintaxe b√°sica
cap migrations add <nome> [op√ß√µes]

# Op√ß√µes dispon√≠veis:
#   --no-stubs     : N√£o criar diret√≥rios espec√≠ficos de SGBD
#   --author <nome>: Especificar autor manualmente
```

**Exemplos:**

```bash
# Migration simples
cap migrations add criar-usuarios

# Com autor customizado
cap migrations add criar-usuarios --author "Jo√£o Silva"

# Sem criar stubs para SGBDs espec√≠ficos
cap migrations add criar-usuarios --no-stubs

# Combinando op√ß√µes
cap migrations add criar-usuarios --author "Maria Santos" --no-stubs
```

**O que acontece:**
1. ‚úÖ Cria arquivo YAML em `db/changelog/common/`
2. ‚úÖ Atualiza `db.changelog-master.yaml`
3. ‚úÖ Detecta autor automaticamente (ou usa `--author`)
4. ‚úÖ Gera timestamp √∫nico para evitar conflitos

**Estrutura gerada:**
```yaml
# db/changelog/common/20250923_014331__criar-usuarios.yaml
databaseChangeLog:
  - changeSet:
      id: 20250923_014331-criar-usuarios
      author: Jo√£o Silva  # Detectado automaticamente
      context: common
      changes:
        # Suas altera√ß√µes aqui
```

### 2. Importar Migration do Entity Framework

```bash
# Sintaxe b√°sica
cap migrations import-ef [op√ß√µes]

# Op√ß√µes obrigat√≥rias:
#   --assembly <path> : Caminho para DLL do EF Core
#   --name <class>    : Nome da classe Migration
#   --provider <type> : Tipo do provider (sqlserver|postgres|mysql)

# Op√ß√µes extras:
#   --author <nome>   : Autor customizado
```

**Exemplos:**

```bash
# Import b√°sico do SQL Server
cap migrations import-ef \
  --assembly ./MyApp/bin/Debug/net8.0/MyApp.dll \
  --name CreateUsersTable \
  --provider sqlserver

# Com autor customizado
cap migrations import-ef \
  --assembly ./MyApp.dll \
  --name CreateUsersTable \
  --provider postgres \
  --author "Jo√£o Silva"

# MySQL
cap migrations import-ef \
  --assembly ./MyApp.dll \
  --name AddProductsTable \
  --provider mysql
```

**O que acontece:**
1. ‚úÖ Carrega assembly .NET especificado
2. ‚úÖ Encontra a classe Migration pelo nome
3. ‚úÖ Executa o m√©todo `Up()` em mem√≥ria
4. ‚úÖ Converte opera√ß√µes EF para YAML Liquibase
5. ‚úÖ Salva em `db/changelog/common/`

**Opera√ß√µes EF Suportadas:**
- ‚úÖ `CreateTable` ‚Üí `createTable`
- ‚úÖ `AddColumn` ‚Üí `addColumn`
- ‚úÖ `InsertData` ‚Üí `insert`
- ‚úÖ `DeleteData` ‚Üí `delete`
- ‚ö†Ô∏è Outras opera√ß√µes ‚Üí SQL gen√©rico com coment√°rio

### 3. Merge de Schemas

```bash
# Sintaxe b√°sica
cap migrations mergeschemas [op√ß√µes]

# Op√ß√µes:
#   --scope <tipo>        : Escopo do merge (common|mssql|postgres|mysql)
#   --include-merged      : Incluir arquivos j√° merged anteriormente
#   --delete-old          : Mover arquivos antigos automaticamente
```

**Exemplos:**

```bash
# Merge do escopo comum
cap migrations mergeschemas --scope common

# Incluindo merges antigos
cap migrations mergeschemas --scope common --include-merged

# Com dele√ß√£o autom√°tica dos arquivos antigos
cap migrations mergeschemas --scope postgres --delete-old

# Processo interativo (padr√£o)
cap migrations mergeschemas --scope mysql
# Pergunta: "Mover arquivos usados para 'db/changelog/deleteSchemas/mysql'? [s/N]"
```

**O que acontece:**
1. ‚úÖ Coleta todos os arquivos .yaml/.yml do escopo
2. ‚úÖ Ordena por timestamp
3. ‚úÖ Consolida em um √∫nico arquivo `__merged-<scope>.yaml`
4. ‚úÖ Atualiza `db.changelog-master.yaml`
5. ‚úÖ Opcionalmente move arquivos antigos para `deleteSchemas/`

---

## üóÉÔ∏è Opera√ß√µes de Banco

### 1. Gerar Plano de Execu√ß√£o

```bash
# Sintaxe b√°sica
cap plan --defaults <arquivo.properties> [op√ß√µes]

# Op√ß√µes:
#   --docker          : Usar Docker em vez de Liquibase CLI local
#   --workdir <dir>   : Diret√≥rio de trabalho
#   --output <arquivo>: Arquivo de sa√≠da para o plano SQL
```

**Exemplos:**

```bash
# Gerar plano b√°sico
cap plan --defaults ./db/changelog/liquibase.properties

# Salvar plano em arquivo
cap plan --defaults ./db/changelog/liquibase.properties --output plan.sql

# Usar Docker
cap plan --defaults ./db/changelog/liquibase.properties --docker

# Com diret√≥rio de trabalho espec√≠fico
cap plan --defaults ./config/liquibase.properties --workdir ./database
```

**Use Cases:**
- üìã **Code Review**: Anexar `plan.sql` em Pull Requests
- üîç **Auditoria**: Revisar mudan√ßas antes de aplicar
- üìä **Documenta√ß√£o**: Hist√≥rico de altera√ß√µes aplicadas

### üí° Detec√ß√£o Autom√°tica de Arquivos (Novo na v1.0.7!)

A partir da v1.0.7, o CapyDb possui **busca recursiva inteligente** para `liquibase.properties`:

**Prioridade de busca:**
1. `./db/changelog/liquibase.properties` (recomendado)
2. `./liquibase.properties` (raiz do projeto)
3. `./config/liquibase.properties`
4. `./database/liquibase.properties`
5. `./migrations/liquibase.properties`
6. `./src/*/db/changelog/liquibase.properties` (estruturas de monorepo)
7. `./apps/*/db/changelog/liquibase.properties` (estruturas de monorepo)
8. `./*/db/changelog/liquibase.properties` (qualquer subdiret√≥rio)
9. **Busca recursiva geral** em todos os subdiret√≥rios (excluindo node_modules e .git)

**Vantagens:**
- ‚úÖ Funciona automaticamente em monorepos complexos
- ‚úÖ Detecta arquivos em estruturas aninhadas
- ‚úÖ Compatibilidade total com Windows (corrigidos problemas de glob patterns)
- ‚úÖ N√£o precisa mais especificar `--defaults` em 99% dos casos

```bash
# Agora voc√™ pode fazer apenas:
cap apply          # Busca automaticamente!
cap plan           # Em qualquer lugar do projeto!
cap status         # Mesmo em estruturas complexas!

# O --defaults ainda funciona se necess√°rio:
cap apply --defaults ./custom/path/liquibase.properties
```

### 2. Aplicar Migrations

```bash
# Sintaxe b√°sica
cap apply --defaults <arquivo.properties> [op√ß√µes]

# Op√ß√µes:
#   --docker          : Usar Docker
#   --workdir <dir>   : Diret√≥rio de trabalho
#   --output <arquivo>: Log da execu√ß√£o
```

**Exemplos:**

```bash
# Aplicar todas as migrations pendentes
cap apply --defaults ./db/changelog/liquibase.properties

# Com log detalhado
cap apply --defaults ./db/changelog/liquibase.properties --output apply.log

# Usando Docker
cap apply --defaults ./db/changelog/liquibase.properties --docker
```

### 3. Verificar Status

```bash
# Ver status das migrations
cap status --defaults ./db/changelog/liquibase.properties

# Com Docker
cap status --defaults ./db/changelog/liquibase.properties --docker
```

### 4. Validar Changelog

```bash
# Validar sintaxe e estrutura
cap validate --defaults ./db/changelog/liquibase.properties

# Com output detalhado
cap validate --defaults ./db/changelog/liquibase.properties --output validation.log
```

### 5. Criar Tags

```bash
# Sintaxe b√°sica
cap tag <nome> --defaults <arquivo.properties> [op√ß√µes]

# Exemplos
cap tag v1.0.0 --defaults ./db/changelog/liquibase.properties
cap tag release-2025-01 --defaults ./db/changelog/liquibase.properties --docker
```

### 6. Remover Tags

```bash
# Sintaxe b√°sica
cap remove-tag <tag> --defaults <arquivo.properties> [op√ß√µes]

# Op√ß√µes:
#   --docker          : Usar Docker
#   --workdir <dir>   : Diret√≥rio de trabalho
```

**Exemplos:**

```bash
# Remover tag existente
cap remove-tag v1.0.0 --defaults ./db/changelog/liquibase.properties

# Com Docker
cap remove-tag release-2025-01 --defaults ./db/changelog/liquibase.properties --docker

# Com diret√≥rio de trabalho espec√≠fico
cap remove-tag old-tag --defaults ./config/liquibase.properties --workdir ./database
```

**O que acontece:**
1. ‚úÖ Cria changeset tempor√°rio com comando SQL UPDATE
2. ‚úÖ Remove a tag da coluna TAG na tabela DATABASECHANGELOG
3. ‚úÖ Limpa arquivo tempor√°rio ap√≥s execu√ß√£o
4. ‚úÖ Valida se a tag existe antes de remover

**Use Cases:**
- üè∑Ô∏è **Corre√ß√£o de Tags**: Remover tags criadas por engano
- üîÑ **Re-tagging**: Limpar tags antigas antes de criar novas
- üßπ **Limpeza**: Manter apenas tags relevantes no hist√≥rico

### 7. Rollback

```bash
# Rollback por contagem
cap rollback count <N> --defaults <arquivo.properties> [op√ß√µes]

# Rollback at√© tag espec√≠fica
cap rollback to-tag <tag> --defaults <arquivo.properties> [op√ß√µes]
```

**Exemplos:**

```bash
# Reverter √∫ltimas 3 migrations
cap rollback count 3 --defaults ./db/changelog/liquibase.properties

# Voltar para tag espec√≠fica
cap rollback to-tag v1.0.0 --defaults ./db/changelog/liquibase.properties

# Com Docker
cap rollback count 1 --defaults ./db/changelog/liquibase.properties --docker
```

---

## üõ†Ô∏è Utilit√°rios

### 1. Doctor - Verifica√ß√£o de Pr√©-requisitos

```bash
# Verifica√ß√£o completa
cap doctor

# Com arquivo de configura√ß√£o espec√≠fico
cap doctor --defaults ./db/changelog/liquibase.properties
```

**O que √© verificado:**
- ‚úÖ **Java**: Instala√ß√£o e vers√£o
- ‚ö†Ô∏è **Docker**: Disponibilidade (opcional)
- ‚ö†Ô∏è **Drivers**: Diret√≥rio `db/drivers/` e arquivos .jar
- ‚úÖ **Arquivo defaults**: Exist√™ncia e conte√∫do
- ‚úÖ **Conex√£o DB**: Teste de conectividade

**Exemplo de sa√≠da:**
```
ü©∫ CapyDb Doctor - Verificando pr√©-requisitos...

‚úÖ Java: java version "17.0.7" 2023-04-18 LTS
‚ö†Ô∏è  Docker: N√£o dispon√≠vel (opcional)
‚ö†Ô∏è  Drivers: Diret√≥rio db/drivers n√£o existe
   Crie o diret√≥rio e adicione os JARs dos drivers JDBC
‚úÖ Defaults: Arquivo db/changelog/liquibase.properties existe
‚úÖ Banco: Conex√£o OK

‚úÖ Todos os pr√©-requisitos est√£o OK!
```

### 2. Drift Detection - Detec√ß√£o de Diverg√™ncias

```bash
# Sintaxe b√°sica
cap drift detect --defaults <arquivo.properties> [op√ß√µes]

# Op√ß√µes:
#   --docker          : Usar Docker
#   --workdir <dir>   : Diret√≥rio de trabalho
#   --output <arquivo>: Arquivo de relat√≥rio (padr√£o: drift-report.xml)
```

**Exemplos:**

```bash
# Detectar diverg√™ncias b√°sicas
cap drift detect --defaults ./db/changelog/liquibase.properties

# Com arquivo de sa√≠da customizado
cap drift detect --defaults ./db/changelog/liquibase.properties --output drift-analysis.xml

# Usando Docker
cap drift detect --defaults ./db/changelog/liquibase.properties --docker
```

**Use Cases:**
- üîç **Schema Validation**: Verificar se DB est√° sincronizado
- üìä **Auditoria**: Detectar mudan√ßas manuais n√£o documentadas
- üö® **CI/CD**: Validar ambiente antes de deploy

### 3. Squash - Consolida√ß√£o de Hist√≥rico

```bash
# Sintaxe b√°sica
cap squash --tag <tag> --defaults <arquivo.properties> [op√ß√µes]

# Op√ß√µes:
#   --docker          : Usar Docker
#   --workdir <dir>   : Diret√≥rio de trabalho
```

**Exemplos:**

```bash
# Consolidar at√© tag espec√≠fica
cap squash --tag v1.0.0 --defaults ./db/changelog/liquibase.properties

# Com Docker
cap squash --tag release-2025 --defaults ./db/changelog/liquibase.properties --docker
```

**O que acontece:**
1. üóúÔ∏è Aplica todo hist√≥rico at√© a tag especificada
2. üìù Gera baseline consolidado do schema atual
3. üì¶ Move arquivos antigos para `db/changelog/archive/`
4. üîÑ Recria changelog master apontando para baseline

**Estrutura ap√≥s squash:**
```
db/changelog/
‚îú‚îÄ‚îÄ archive/
‚îÇ   ‚îî‚îÄ‚îÄ squash-20250923-014500/
‚îÇ       ‚îú‚îÄ‚îÄ common/           # Migrations antigas
‚îÇ       ‚îú‚îÄ‚îÄ mssql/
‚îÇ       ‚îî‚îÄ‚îÄ postgres/
‚îú‚îÄ‚îÄ common/
‚îÇ   ‚îî‚îÄ‚îÄ baseline-20250923-014500.yaml  # Schema consolidado
‚îî‚îÄ‚îÄ db.changelog-master.yaml           # Aponta para baseline
```

### 4. Conversor de INSERTs SQL

```bash
# Sintaxe b√°sica
cap convert-inserts --input <arquivo.sql> --output <arquivo.yaml> [op√ß√µes]

# Op√ß√µes:
#   --input <path>    : Arquivo SQL com INSERTs (obrigat√≥rio)
#   --output <path>   : Arquivo YAML de sa√≠da (obrigat√≥rio)
#   --table <nome>    : Nome da tabela (opcional, detectado automaticamente)
#   --author <nome>   : Autor do changeset (opcional)
```

**Exemplos:**

```bash
# Convers√£o b√°sica
cap convert-inserts --input ./data.sql --output ./changelog.yaml

# Especificar tabela e autor
cap convert-inserts \
  --input ./usuarios.sql \
  --output ./db/changelog/common/seed-usuarios.yaml \
  --table usuarios \
  --author "Jo√£o Silva"

# Converter m√∫ltiplas INSERTs
cap convert-inserts --input ./seed-data.sql --output ./changelog-seed.yaml
```

**Formato de entrada (SQL):**
```sql
INSERT INTO usuarios (id, nome, email, ativo) VALUES (1, 'Jo√£o Silva', 'joao@email.com', 1);
INSERT INTO usuarios (id, nome, email, ativo) VALUES (2, 'Maria Santos', 'maria@email.com', 1);
INSERT INTO usuarios (id, nome, email, ativo) VALUES (3, 'Pedro Oliveira', 'pedro@email.com', 0);
```

**Formato de sa√≠da (YAML):**
```yaml
databaseChangeLog:
  - changeSet:
      id: convert-inserts-20250930-101530
      author: Jo√£o Silva
      context: common
      changes:
        - insert:
            tableName: usuarios
            columns:
              - column: { name: id, value: 1 }
              - column: { name: nome, value: 'Jo√£o Silva' }
              - column: { name: email, value: 'joao@email.com' }
              - column: { name: ativo, value: 1 }
        - insert:
            tableName: usuarios
            columns:
              - column: { name: id, value: 2 }
              - column: { name: nome, value: 'Maria Santos' }
              - column: { name: email, value: 'maria@email.com' }
              - column: { name: ativo, value: 1 }
```

**Use Cases:**
- üìä **Seed Data**: Converter dados iniciais para Liquibase
- üîÑ **Migra√ß√£o**: Importar dados de SQL legado
- üß™ **Testes**: Criar dados de teste em formato port√°vel
- üì¶ **Fixtures**: Preparar dados para diferentes ambientes

**Recursos:**
- ‚úÖ Detecta automaticamente nome da tabela
- ‚úÖ Preserva tipos de dados (strings, n√∫meros, booleanos, NULL)
- ‚úÖ Suporta m√∫ltiplos INSERTs no mesmo arquivo
- ‚úÖ Escapa caracteres especiais corretamente
- ‚úÖ Gera changeSet com ID √∫nico baseado em timestamp

---

## üìä Data Seeding (Carga de Dados)

### Vis√£o Geral

O CapyDb oferece um sistema completo para gerenciar dados iniciais (seed data) separadamente das migrations de schema. Isso permite:

- ‚úÖ Versionamento independente de dados e schema
- ‚úÖ Gera√ß√£o autom√°tica de changesets a partir de CSV
- ‚úÖ Infer√™ncia inteligente de tipos de dados
- ‚úÖ Rollback espec√≠fico de dados sem afetar o schema
- ‚úÖ Filtragem por label (`data-seed`)

### 1. Gerar Changelog a partir de CSV

```bash
# Sintaxe b√°sica
cap carga from-csv --input <arquivo.csv> --table <tabela> [op√ß√µes]

# Op√ß√µes obrigat√≥rias:
#   --input, -i <path>    : Caminho para arquivo CSV
#   --table, -t <nome>    : Nome da tabela de destino

# Op√ß√µes adicionais:
#   --output, -o <path>   : Arquivo YAML de sa√≠da (padr√£o: db/changelog/carga-updates/YYYYMMDD__carga-<tabela>.yaml)
#   --author <nome>       : Nome do autor (padr√£o: CapyDb)
#   --context <contexto>  : Contexto do changeset (padr√£o: common)
#   --add-to-master       : Adicionar automaticamente ao db.changelog-master.yaml
```

**Exemplos:**

```bash
# Gera√ß√£o b√°sica
cap carga from-csv --input db/carga/Users.csv --table Users

# Com todas as op√ß√µes
cap carga from-csv \
  --input db/carga/Countries.csv \
  --table TabelaAuxiliarCountries \
  --author "Evellyn Fernandes" \
  --output db/changelog/carga-updates/countries.yaml \
  --add-to-master

# Forma abreviada
cap carga from-csv -i db/carga/Cities.csv -t Cities

# M√∫ltiplos arquivos em lote
for file in db/carga/*.csv; do
  table=$(basename "$file" .csv)
  cap carga from-csv -i "$file" -t "$table" --add-to-master
done
```

**Infer√™ncia Autom√°tica de Tipos:**

O comando analisa os nomes das colunas do CSV e infere os tipos automaticamente:

| Padr√£o de Nome | Tipo Inferido | Exemplos |
|----------------|---------------|----------|
| `*Id`, `PublicId` | UUID | `Id`, `UserId`, `PublicId` |
| `Excluido`, `Ativo`, `Is*`, `Has*` | BOOLEAN | `Excluido`, `Ativo`, `IsActive`, `HasPermission` |
| `Data*`, `Date*`, `*Timestamp`, `*At` | TIMESTAMP | `DataCriacao`, `DateCreated`, `CreatedAt`, `UpdatedAt` |
| `*Num`, `*Numero`, `Count`, `Quantidade` | NUMERIC | `CodigoNum`, `Age`, `Count`, `Quantidade` |
| Outros | STRING | `Name`, `Email`, `Description` |

**Resolu√ß√£o Autom√°tica de Depend√™ncias:**

O CapyDb detecta automaticamente as depend√™ncias entre tabelas e ordena os changesets corretamente:

- ‚úÖ **Detec√ß√£o de Foreign Keys**: Colunas terminadas em `Id` (exceto `Id` e `PublicId`) s√£o consideradas FKs
- ‚úÖ **Resolu√ß√£o de Nomes**: Remove prefixos como `TabelaAuxiliar` para encontrar tabelas referenciadas
- ‚úÖ **Ordena√ß√£o Topol√≥gica**: Tabelas sem depend√™ncias s√£o carregadas primeiro
- ‚úÖ **Detec√ß√£o de Ciclos**: Alerta sobre depend√™ncias circulares entre tabelas
- ‚úÖ **Matching Inteligente**: Busca tabelas por nome exato, com prefixo, plural, ou parcial

**Exemplo de Depend√™ncias:**
```
ModuloCategoria.csv tem coluna "ModuloId"
  ‚Üì CapyDb detecta FK para "Modulo"
  ‚Üì Ordena automaticamente:
    1. Modulo.csv           (sem depend√™ncias)
    2. ModuloCategoria.csv  (depende de Modulo)
```

**Exemplo de CSV:**
```csv
Id,Name,Email,IsActive,CreatedAt,Age
cc53be96-29d4-46ec-882d-042ad26f3aa5,Jo√£o Silva,joao@email.com,true,2024-01-01,30
6771123b-a632-423d-9c8a-f1ec7fd4b438,Maria Santos,maria@email.com,true,2024-01-02,25
```

**YAML Gerado:**
```yaml
databaseChangeLog:
  - changeSet:
      id: 20251017-carga-users
      author: CapyDb
      context: common
      labels: data-seed
      changes:
        - loadData:
            tableName: Users
            file: db/carga/Users.csv
            relativeToChangelogFile: false
            separator: ","
            quotchar: '"'
            encoding: UTF-8
            columns:
              - column:
                  name: Id
                  type: UUID
              - column:
                  name: Name
                  type: STRING
              - column:
                  name: Email
                  type: STRING
              - column:
                  name: IsActive
                  type: BOOLEAN
              - column:
                  name: CreatedAt
                  type: TIMESTAMP
              - column:
                  name: Age
                  type: NUMERIC
      rollback:
        - delete:
            tableName: Users
```

### 2. Aplicar Dados de Seed

```bash
# Sintaxe b√°sica
cap carga update --defaults <arquivo.properties> [op√ß√µes]

# Op√ß√µes:
#   --docker          : Usar Docker
#   --workdir <dir>   : Diret√≥rio de trabalho
#   --output <arquivo>: Log da execu√ß√£o
#   --logs            : Exibir logs detalhados
```

**Exemplos:**

```bash
# Aplicar todos os changesets com label 'data-seed'
cap carga update --defaults ./db/changelog/liquibase.properties

# Com logs detalhados
cap carga update --defaults ./db/changelog/liquibase.properties --logs

# Usando Docker
cap carga update --defaults ./db/changelog/liquibase.properties --docker
```

**O que acontece:**
1. ‚úÖ Liquibase filtra changesets com label `data-seed`
2. ‚úÖ Aplica apenas os changesets de dados ainda n√£o executados
3. ‚úÖ Registra execu√ß√£o na tabela `DATABASECHANGELOG`
4. ‚úÖ Pula changesets de schema (sem label ou com outras labels)

### 3. Remover e Reaplicar Dados (Desenvolvimento)

```bash
# Sintaxe b√°sica
cap carga drop-all --defaults <arquivo.properties> [op√ß√µes]

# Op√ß√µes:
#   --docker          : Usar Docker
#   --workdir <dir>   : Diret√≥rio de trabalho
#   --logs            : Exibir logs detalhados
```

**Exemplos:**

```bash
# Remover todos os dados e reaplicar
cap carga drop-all --defaults ./db/changelog/liquibase.properties

# Com Docker
cap carga drop-all --defaults ./db/changelog/liquibase.properties --docker
```

**‚ö†Ô∏è ATEN√á√ÉO:**
- Remove TODOS os dados das tabelas referenciadas nos changesets de data-seed
- √ötil para desenvolvimento e testes
- **N√ÉO usar em produ√ß√£o sem backup!**

### 4. Reset Completo (Schema + Dados)

```bash
# Sintaxe b√°sica
cap carga reset --defaults <arquivo.properties> [op√ß√µes]

# Op√ß√µes:
#   --docker          : Usar Docker
#   --workdir <dir>   : Diret√≥rio de trabalho
#   --logs            : Exibir logs detalhados
```

**Exemplos:**

```bash
# CUIDADO: Apaga TODO o banco e recria
cap carga reset --defaults ./db/changelog/liquibase.properties

# Com confirma√ß√£o
read -p "Tem certeza que deseja resetar o banco? [s/N] " -n 1 -r
echo
if [[ $REPLY =~ ^[Ss]$ ]]; then
    cap carga reset --defaults ./db/changelog/liquibase.properties
fi
```

**‚ö†Ô∏è PERIGO:**
- Executa `DROP ALL` no banco inteiro
- Recria schema e dados do zero
- **EXTREMAMENTE DESTRUTIVO**
- Requer confirma√ß√£o manual

### 5. Rollback de Dados

```bash
# Sintaxe b√°sica
cap carga rollback --defaults <arquivo.properties> [op√ß√µes]

# Op√ß√µes:
#   --docker          : Usar Docker
#   --workdir <dir>   : Diret√≥rio de trabalho
#   --logs            : Exibir logs detalhados
```

**Exemplos:**

```bash
# Reverter √∫ltimo changeset de dados
cap carga rollback --defaults ./db/changelog/liquibase.properties

# Com logs
cap carga rollback --defaults ./db/changelog/liquibase.properties --logs
```

**O que acontece:**
1. ‚úÖ Identifica √∫ltimo changeset com label `data-seed`
2. ‚úÖ Executa bloco `rollback` do changeset
3. ‚úÖ Remove registro da tabela `DATABASECHANGELOG`
4. ‚úÖ Permite reaplicar o changeset posteriormente

### 6. Status de Dados

```bash
# Sintaxe b√°sica
cap carga status --defaults <arquivo.properties> [op√ß√µes]

# Op√ß√µes:
#   --docker          : Usar Docker
#   --workdir <dir>   : Diret√≥rio de trabalho
```

**Exemplos:**

```bash
# Ver status dos changesets de dados
cap carga status --defaults ./db/changelog/liquibase.properties

# Com Docker
cap carga status --defaults ./db/changelog/liquibase.properties --docker
```

**Sa√≠da:**
```
3 changesets have not been applied to sa@jdbc:sqlserver://localhost:1433;...
  db/changelog/carga-updates/20251017__carga-countries.yaml::20251017-carga-countries::Evellyn Fernandes
  db/changelog/carga-updates/20251017__carga-cities.yaml::20251017-carga-cities::Evellyn Fernandes
  db/changelog/carga-updates/20251017__carga-users.yaml::20251017-carga-users::Evellyn Fernandes
```

### Workflow Completo de Data Seeding

```bash
# 1. Preparar CSV
cat > db/carga/Countries.csv << EOF
Id,Name,Code,Population,IsActive
1,Brasil,BR,212000000,true
2,Estados Unidos,US,331000000,true
3,Argentina,AR,45000000,true
EOF

# 2. Gerar changelog
cap carga from-csv \
  --input db/carga/Countries.csv \
  --table Countries \
  --author "Evellyn Fernandes" \
  --add-to-master

# 3. Verificar arquivo gerado
cat db/changelog/carga-updates/20251017__carga-countries.yaml

# 4. Aplicar dados
cap carga update --defaults db/changelog/liquibase.properties

# 5. Verificar status
cap carga status --defaults db/changelog/liquibase.properties

# 6. Se necess√°rio, reverter
cap carga rollback --defaults db/changelog/liquibase.properties
```

### Estrutura de Projeto com Data Seeding

```
projeto/
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ changelog/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ common/              # Schema migrations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 20250101_120000__create-tables.yaml
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 20250102_143000__add-columns.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ carga-updates/       # Data seed migrations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 20251017__carga-countries.yaml
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 20251017__carga-cities.yaml
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 20251017__carga-users.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db.changelog-master.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ liquibase.properties
‚îÇ   ‚îú‚îÄ‚îÄ carga/                   # CSV source files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Countries.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Cities.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Users.csv
‚îÇ   ‚îî‚îÄ‚îÄ drivers/
‚îî‚îÄ‚îÄ src/
```

### Resolu√ß√£o Autom√°tica de Depend√™ncias

O CapyDb CLI v1.2.3+ inclui um sistema inteligente de resolu√ß√£o de depend√™ncias que:

**Como Funciona:**

1. **Escaneia todos os changesets** em `db/changelog/carga-updates/`
2. **L√™ os cabe√ßalhos CSV** de cada arquivo referenciado
3. **Detecta Foreign Keys** - colunas terminadas em `Id` (exceto `Id` e `PublicId`)
4. **Resolve nomes de tabelas** - remove prefixos como `TabelaAuxiliar`
5. **Ordena topologicamente** - coloca depend√™ncias primeiro
6. **Atualiza db.changelog-carga.yaml** com a ordem correta

**Algoritmo de Matching:**

```
Coluna CSV: "ModuloId"
  ‚Üì Remove "Id" ‚Üí "Modulo"
  ‚Üì Busca por:
    1. Match exato: "Modulo"
    2. Com prefixo: "TabelaAuxiliarModulo"
    3. Plural: "Modulos" ou "TabelaAuxiliarModulos"
    4. Parcial: termina com "Modulo"
  ‚Üì Encontrado: adiciona depend√™ncia
```

**Exemplo Pr√°tico:**

```bash
# Voc√™ tem estes CSVs:
# - Modulo.csv (sem FKs)
# - ModuloCategoria.csv (tem ModuloId ‚Üí FK para Modulo)
# - FundamentacoesLegais.csv (tem LeisId ‚Üí FK para TabelaAuxiliarLeis)

# Ao executar:
cap carga from-csv -i db/carga/ModuloCategoria.csv -t ModuloCategoria --add-to-master
cap carga from-csv -i db/carga/Modulo.csv -t Modulo --add-to-master
cap carga from-csv -i db/carga/FundamentacoesLegais.csv -t FundamentacoesLegais --add-to-master

# O CapyDb reordena automaticamente em db.changelog-carga.yaml:
#   1. Modulo (sem depend√™ncias)
#   2. TabelaAuxiliarLeis (sem depend√™ncias)
#   3. ModuloCategoria (depende de Modulo)
#   4. FundamentacoesLegais (depende de Leis)

# Resultado: zero erros de FK constraint!
```

**Tratamento de Casos Especiais:**

- **Depend√™ncias n√£o encontradas**: Aviso amarelo, mas continua execu√ß√£o
- **Depend√™ncias circulares**: Detectadas e reportadas com erro
- **M√∫ltiplas FKs**: Todas s√£o detectadas e consideradas
- **Prefixos customizados**: Sistema tenta m√∫ltiplas varia√ß√µes

### Use Cases

**1. Dados de Refer√™ncia:**
```bash
# Pa√≠ses, estados, cidades
cap carga from-csv -i db/carga/Countries.csv -t Countries --add-to-master
cap carga from-csv -i db/carga/States.csv -t States --add-to-master
cap carga from-csv -i db/carga/Cities.csv -t Cities --add-to-master
cap carga update --defaults db/changelog/liquibase.properties
```

**2. Configura√ß√µes do Sistema:**
```bash
# Configura√ß√µes, permiss√µes, roles
cap carga from-csv -i db/carga/SystemConfig.csv -t SystemConfig --add-to-master
cap carga from-csv -i db/carga/Roles.csv -t Roles --add-to-master
cap carga update --defaults db/changelog/liquibase.properties
```

**3. Dados de Teste:**
```bash
# Ambiente de desenvolvimento
cap carga from-csv -i db/carga/TestUsers.csv -t Users --context dev
cap carga update --defaults db/changelog/liquibase-dev.properties
```

---

## üë§ Sistema de Autores

### Detec√ß√£o Autom√°tica (ordem de prioridade)

1. **Par√¢metro `--author`** (prioridade m√°xima)
2. **Vari√°vel `CAPY_AUTHOR`** (configura√ß√£o espec√≠fica)
3. **Git user.name** (configura√ß√£o local)
4. **Vari√°veis do sistema** (`GIT_AUTHOR_NAME`, `USER`, `USERNAME`, `LOGNAME`)
5. **Fallback** (`capydb`)

### Configura√ß√£o por Ambiente

#### Desenvolvimento Local

```bash
# Configurar Git (detectado automaticamente)
git config user.name "Jo√£o Silva"

# Ou usar vari√°vel espec√≠fica
export CAPY_AUTHOR="Jo√£o Silva"  # Linux/Mac
set CAPY_AUTHOR=Jo√£o Silva       # Windows
```

#### CI/CD Pipelines

**GitHub Actions:**
```yaml
env:
  CAPY_AUTHOR: "${{ github.actor }}"  # Nome do usu√°rio que fez commit
```

**Azure DevOps:**
```yaml
variables:
  CAPY_AUTHOR: "$(Build.RequestedFor)"  # Nome do usu√°rio
```

**Jenkins:**
```groovy
environment {
    CAPY_AUTHOR = "${env.BUILD_USER}"
}
```

### Exemplos Pr√°ticos

```bash
# Detec√ß√£o autom√°tica (usa Git)
cap migrations add criar-produtos
# author: Jo√£o Silva (do Git)

# Autor espec√≠fico
cap migrations add criar-produtos --author "Maria Santos"
# author: Maria Santos

# Via vari√°vel de ambiente
export CAPY_AUTHOR="CI/CD Pipeline"
cap migrations add criar-produtos
# author: CI/CD Pipeline

# Import EF com autor
cap migrations import-ef \
  --assembly MyApp.dll \
  --name CreateProducts \
  --provider sqlserver \
  --author "Jo√£o Silva"
```

---

## ‚öôÔ∏è Configura√ß√£o Avan√ßada

### Arquivo liquibase.properties

**Exemplo completo:**
```properties
# Configura√ß√£o do banco
url=jdbc:sqlserver://localhost:1433;databaseName=MyApp;trustServerCertificate=true
username=sa
password=MyPassword123

# Configura√ß√£o do changelog
changeLogFile=db/changelog/db.changelog-master.yaml

# Drivers (se usando CLI local)
classpath=db/drivers/mssql-jdbc-12.4.2.jre11.jar

# Configura√ß√µes extras
logLevel=INFO
contexts=common,production
labels=!test
```

### Estrutura de Projeto Recomendada

```
projeto/
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ changelog/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ common/              # Migrations de schema port√°veis
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 20250101_120000__initial.yaml
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 20250102_143000__add-users.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ carga-updates/       # Migrations de data seeding
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 20251017__carga-countries.yaml
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 20251017__carga-cities.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mssql/               # Espec√≠fico SQL Server
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgres/            # Espec√≠fico PostgreSQL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mysql/               # Espec√≠fico MySQL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ archive/             # Arquivos ap√≥s squash
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deleteSchemas/       # Arquivos ap√≥s merge
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db.changelog-master.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ liquibase.properties
‚îÇ   ‚îú‚îÄ‚îÄ carga/                   # Arquivos CSV para data seeding
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Countries.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Cities.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Users.csv
‚îÇ   ‚îî‚îÄ‚îÄ drivers/                 # JARs dos drivers JDBC
‚îÇ       ‚îú‚îÄ‚îÄ mssql-jdbc-12.4.2.jre11.jar
‚îÇ       ‚îú‚îÄ‚îÄ postgresql-42.7.0.jar
‚îÇ       ‚îî‚îÄ‚îÄ mysql-connector-j-8.2.0.jar
‚îú‚îÄ‚îÄ src/
‚îî‚îÄ‚îÄ README.md
```

### Configura√ß√£o de Docker

**docker-compose.yml para desenvolvimento:**
```yaml
version: '3.8'
services:
  capy-migrations:
    image: liquibase/liquibase:latest
    volumes:
      - ./db/changelog:/liquibase/changelog
      - ./db/drivers:/liquibase/drivers
    environment:
      - LIQUIBASE_COMMAND_URL=jdbc:sqlserver://sqlserver:1433;databaseName=MyApp
      - LIQUIBASE_COMMAND_USERNAME=sa
      - LIQUIBASE_COMMAND_PASSWORD=MyPassword123
      - LIQUIBASE_COMMAND_CHANGELOG_FILE=changelog/db.changelog-master.yaml
```

**Uso com Docker:**
```bash
# Todos os comandos suportam --docker
cap status --defaults ./db/changelog/liquibase.properties --docker
cap apply --defaults ./db/changelog/liquibase.properties --docker
cap plan --defaults ./db/changelog/liquibase.properties --docker --output plan.sql
```

---

## üêõ Troubleshooting

### Problemas Comuns

#### 1. Emojis n√£o aparecem no terminal

**Solu√ß√£o autom√°tica**: O CapyDb CLI agora configura UTF-8 automaticamente

**Solu√ß√£o manual (Windows):**
```cmd
# No Command Prompt
chcp 65001

# No PowerShell
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8
```

#### 2. Java n√£o encontrado

```bash
# Verificar se Java est√° instalado
java -version

# Se n√£o estiver, instalar OpenJDK 8+
# Windows: https://adoptium.net/
# Linux: sudo apt install openjdk-11-jre
# Mac: brew install openjdk@11
```

#### 3. Liquibase n√£o encontrado

**Op√ß√£o 1: Usar Docker (recomendado)**
```bash
# Instalar Docker Desktop
# Usar --docker em todos os comandos
cap doctor --docker
```

**Op√ß√£o 2: Instalar Liquibase CLI**
```bash
# Windows (Chocolatey)
choco install liquibase

# Mac (Homebrew)
brew install liquibase

# Linux
# Baixar de https://www.liquibase.org/download
```

#### 4. Drivers JDBC n√£o encontrados

```bash
# Criar diret√≥rio
mkdir -p db/drivers

# Baixar drivers necess√°rios:
# SQL Server: https://docs.microsoft.com/en-us/sql/connect/jdbc/download-microsoft-jdbc-driver-for-sql-server
# PostgreSQL: https://jdbc.postgresql.org/download.html
# MySQL: https://dev.mysql.com/downloads/connector/j/

# Copiar .jar para db/drivers/
cp mssql-jdbc-*.jar db/drivers/
```

#### 5. Erro de conex√£o com banco

```bash
# Verificar conectividade
cap doctor --defaults ./db/changelog/liquibase.properties

# Verificar configura√ß√µes no liquibase.properties
# - url correto
# - username/password v√°lidos
# - banco existe
# - firewall permite conex√£o
```

#### 6. Migration duplicada

```bash
# Verificar conflitos no master
cat db/changelog/db.changelog-master.yaml

# Se necess√°rio, usar merge
cap migrations mergeschemas --scope common
```

### Logs e Debug

#### Habilitar modo debug

```bash
# Vari√°vel de ambiente para debug detalhado
export CAPY_DEBUG=true  # Linux/Mac
set CAPY_DEBUG=true     # Windows

# Executar comando
cap plan --defaults ./db/changelog/liquibase.properties
```

**Output com debug:**
```
[DEBUG] Command: liquibase --defaultsFile="./db/changelog/liquibase.properties" updateSQL
[DEBUG] WorkDir: /caminho/do/projeto
[DEBUG] ExitCode: 0

-- Liquibase output aqui --
```

#### Verificar logs do Liquibase

```bash
# Salvar output em arquivo
cap apply --defaults ./db/changelog/liquibase.properties --output apply.log

# Ver logs detalhados
cap validate --defaults ./db/changelog/liquibase.properties --output validation.log
```

---

## üìö Exemplos de Workflows

### Workflow de Desenvolvimento

```bash
# 1. Criar nova migration
cap migrations add adicionar-tabela-produtos --author "Jo√£o Silva"

# 2. Editar arquivo gerado
# db/changelog/common/20250923_120000__adicionar-tabela-produtos.yaml

# 3. Verificar plano
cap plan --defaults ./db/changelog/liquibase.properties --output plan.sql

# 4. Aplicar em desenvolvimento
cap apply --defaults ./db/changelog/liquibase.properties

# 5. Verificar status
cap status --defaults ./db/changelog/liquibase.properties

# 6. Criar tag para release
cap tag v1.2.0 --defaults ./db/changelog/liquibase.properties

# 7. Se necess√°rio, remover tag antiga
cap remove-tag v1.1.0 --defaults ./db/changelog/liquibase.properties
```

### Workflow de CI/CD

```bash
# Em build pipeline
export CAPY_AUTHOR="$CI_COMMIT_AUTHOR"

# Verificar pr√©-requisitos
cap doctor --defaults ./db/changelog/liquibase.properties

# Gerar plano para review
cap plan --defaults ./db/changelog/liquibase.properties --output artifacts/plan.sql

# Em deploy pipeline
cap apply --defaults ./db/changelog/liquibase.properties

# Criar tag de deploy
cap tag "deploy-$(date +%Y%m%d-%H%M%S)" --defaults ./db/changelog/liquibase.properties
```

### Workflow de Migra√ß√£o de EF Core

```bash
# 1. Compilar projeto EF
dotnet build MyApp.sln

# 2. Importar migration espec√≠fica
cap migrations import-ef \
  --assembly ./MyApp/bin/Debug/net8.0/MyApp.dll \
  --name AddProductsTable \
  --provider sqlserver \
  --author "Maria Santos"

# 3. Verificar resultado
cat db/changelog/common/20250923_*__addproductstable.yaml

# 4. Testar em desenvolvimento
cap apply --defaults ./db/changelog/liquibase.properties
```

### Workflow de Convers√£o de Dados

```bash
# 1. Exportar dados de tabela existente (exemplo PostgreSQL)
psql -d mydb -c "COPY usuarios TO '/tmp/usuarios.sql' WITH (FORMAT text)"

# 2. Ou criar arquivo SQL manualmente
cat > seed-data.sql << EOF
INSERT INTO usuarios (id, nome, email) VALUES (1, 'Admin', 'admin@email.com');
INSERT INTO usuarios (id, nome, email) VALUES (2, 'User', 'user@email.com');
EOF

# 3. Converter para formato Liquibase
cap convert-inserts \
  --input ./seed-data.sql \
  --output ./db/changelog/common/20250930__seed-usuarios.yaml \
  --author "Sistema"

# 4. Adicionar ao master
# (editar db.changelog-master.yaml)

# 5. Aplicar seed data
cap apply --defaults ./db/changelog/liquibase.properties

# 6. Verificar dados
cap status --defaults ./db/changelog/liquibase.properties
```

---

## üéØ Melhores Pr√°ticas

### Naming Conventions

- **Migrations**: Use kebab-case (`criar-tabela-usuarios`)
- **Tags**: Use semantic versioning (`v1.2.0`) ou timestamp (`deploy-20250923-1200`)
- **Autores**: Nome completo ou username consistente

### Organiza√ß√£o de Arquivos

- **Common**: Mudan√ßas port√°veis entre SGBDs
- **Espec√≠ficos**: SQL espec√≠fico por banco quando necess√°rio
- **Archive**: Manter hist√≥rico ap√≥s squash
- **Drivers**: Vers√µes compat√≠veis e atualizadas

### Seguran√ßa

- **Nunca** commitar senhas em `liquibase.properties`
- Usar vari√°veis de ambiente para credenciais
- Configurar `.gitignore` adequadamente:

```gitignore
# Credentials
db/changelog/liquibase.properties
*.secret

# Temporary files
*.log
plan*.sql
drift-report*.xml
```

### Performance

- Fazer **squash** periodicamente para manter hist√≥rico limpo
- Usar **contexts** e **labels** para ambientes espec√≠ficos
- Monitorar tamanho do changelog master

---

**Documenta√ß√£o gerada para CapyDb CLI v1.2.3**
*√öltima atualiza√ß√£o: 2025-10-27*

## üÜï Novidades na v1.2.3

### Data Seeding e Gerenciamento de Dados
- ‚úÖ **Comando `cap carga from-csv`** - Gera√ß√£o autom√°tica de changesets a partir de CSV
- ‚úÖ **Infer√™ncia Inteligente de Tipos** - Detecta automaticamente UUID, BOOLEAN, TIMESTAMP, NUMERIC, STRING
- ‚úÖ **Resolu√ß√£o Autom√°tica de Depend√™ncias** - Detecta FKs dos cabe√ßalhos CSV e ordena tabelas automaticamente
- ‚úÖ **Ordena√ß√£o Topol√≥gica** - Ordena√ß√£o inteligente previne viola√ß√µes de FK durante carga de dados
- ‚úÖ **Detec√ß√£o de Depend√™ncias Circulares** - Alerta sobre refer√™ncias circulares entre tabelas
- ‚úÖ **Comandos de Gerenciamento** - update, drop-all, reset, rollback, status para dados
- ‚úÖ **Filtragem por Label** - Usa label `data-seed` para opera√ß√µes espec√≠ficas
- ‚úÖ **Auto-add to Master** - Op√ß√£o para adicionar automaticamente ao master changelog

### Melhorias no Pacote
- ‚úÖ **Depend√™ncias Embutidas** - CapyDb.Core, Runner e Writers agora fazem parte do CLI
- ‚úÖ **Pacote NuGet Limpo** - Sem depend√™ncias externas listadas
- ‚úÖ **Multi-target Completo** - Suporte total para .NET 8.0 e .NET 9.0

### Vers√µes Anteriores (v1.0.7)
- ‚úÖ **Busca Recursiva Aprimorada** - O sistema agora busca `liquibase.properties` em m√∫ltiplos locais automaticamente
- ‚úÖ **Suporte Completo a Windows** - Corrigidos problemas com padr√µes glob no Windows
- ‚úÖ **Suporte a Monorepos** - Funciona perfeitamente com estruturas complexas (`apps/*/`, `src/*/`)
- ‚úÖ **Detec√ß√£o Inteligente de Assemblies** - Melhor suporte para EF Core em projetos grandes
- ‚úÖ **Multiplataforma** - Testado e validado no Windows, Linux e macOS

---

## üìë Resumo de Comandos

### Migrations
- `cap migrations add <nome>` - Criar nova migration
- `cap migrations import-ef` - Importar do EF Core
- `cap migrations mergeschemas` - Consolidar migrations

### Opera√ß√µes de Banco
- `cap plan` - Gerar plano SQL
- `cap apply` - Aplicar migrations
- `cap status` - Ver status
- `cap validate` - Validar changelog
- `cap tag <nome>` - Criar tag
- `cap remove-tag <tag>` - Remover tag
- `cap rollback count <N>` - Reverter N migrations
- `cap rollback to-tag <tag>` - Reverter at√© tag

### Data Seeding (Carga de Dados)
- `cap carga from-csv` - Gerar changelog a partir de CSV
- `cap carga update` - Aplicar dados de seed (label: data-seed)
- `cap carga drop-all` - Remover e reaplicar dados
- `cap carga reset` - Reset completo (schema + dados)
- `cap carga rollback` - Reverter √∫ltimo changeset de dados
- `cap carga status` - Ver status dos dados de seed

### Utilit√°rios
- `cap doctor` - Verificar pr√©-requisitos
- `cap drift detect` - Detectar diverg√™ncias
- `cap squash --tag <tag>` - Consolidar hist√≥rico
- `cap convert-inserts` - Converter INSERTs SQL
- `cap bye` - Despedida